{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 Multiclass Logistic Regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "imcNmFXhPdCh"
      },
      "source": [
        "# Import our standard libraries.\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns  # for nicer plots\n",
        "sns.set(style='darkgrid')  # default style\n",
        "import tensorflow as tf\n",
        "np.set_printoptions(precision=3, suppress=True)  # improve float readability\n",
        "from sklearn import datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4mROCY5wAX4"
      },
      "source": [
        "## Iris Classification\n",
        "\n",
        "We will train a classifier to predict 3 iris varieties from 4 features of each flower. Note: we are not doing image classification here!\n",
        "\n",
        "![An image](https://drive.google.com/uc?id=12gf4Q0K45gvw-tUDt_sWsbAl-f0klhib)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37XEUjK4ulzp",
        "outputId": "a505c21f-371c-45f0-c5b1-aa1ef96f3d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "Y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "class_names = iris.target_names\n",
        "\n",
        "print('X shape:', X.shape)\n",
        "print('Y shape:', Y.shape)\n",
        "print('feature names:', feature_names)\n",
        "print('class names:', class_names)\n",
        "print('First example:', X[0], Y[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (150, 4)\n",
            "Y shape: (150,)\n",
            "feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "class names: ['setosa' 'versicolor' 'virginica']\n",
            "First example: [5.1 3.5 1.4 0.2] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3GC13Sf219q"
      },
      "source": [
        "## Data Processing\n",
        "\n",
        "* Shuffle\n",
        "* Split into train/test\n",
        "* Apply mean and variance normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sa_lrwU1oiT"
      },
      "source": [
        "np.random.seed(0)\n",
        "shuffled_indices = np.random.permutation(range(len(Y)))\n",
        "X = X[shuffled_indices]\n",
        "Y = Y[shuffled_indices]\n",
        "\n",
        "X_train = X[0:100]\n",
        "Y_train = Y[0:100]\n",
        "X_test = X[100:150]\n",
        "Y_test = Y[100:150]\n",
        "\n",
        "X_train_means = np.mean(X_train, axis=0)\n",
        "X_train_stds = np.std(X_train, axis=0)\n",
        "X_train = (X_train - X_train_means) / X_train_stds\n",
        "X_test = (X_test - X_train_means)/ X_train_stds"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jIgCYbiVAz3"
      },
      "source": [
        "## Sparse vs Dense Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bcduWsAbCRl",
        "outputId": "a776f9b9-453c-42c5-95cc-94b7793e438b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Convert Y from sparse to dense if needed\n",
        "# one-hot [0, 0, 1] -> 2\n",
        "# one-hot [0, 1, 0] -> 1\n",
        "# one-hot [1, 0, 0] -> 0\n",
        "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
        "print(Y_train_dense.shape)\n",
        "print(Y_train_dense[:6])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 3)\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS7LIrIlVd2E"
      },
      "source": [
        "## Softmax Regression Functional Form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdGfEoDovBm"
      },
      "source": [
        "We will use *softmax regression*, which extends *logistic regression* to the multiclass setting. Our model will make predictions for input examples $X$ by:\n",
        "\n",
        "\\begin{align}\n",
        "\\hat{Y} = h_W(X) = \\phi(XW^T) =\n",
        "\\phi\\begin{pmatrix}\n",
        "x_{0,0} & x_{0,1} & x_{0,2} & x_{0,3} \\\\\n",
        "x_{1,0} & x_{1,1} & x_{1,2} & x_{1,3} \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
        "x_{m-1,0} & x_{m-1,1} & x_{m-1,2} & x_{m-1,3} \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "w_{0,0} & w_{1,0} & w_{2,0} \\\\\n",
        "w_{0,1} & w_{1,1} & w_{2,1} \\\\\n",
        "w_{0,2} & w_{1,2} & w_{2,2} \\\\\n",
        "w_{0,3} & w_{1,3} & w_{2,3} \\\\\n",
        "\\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "A few notes about this computation:\n",
        "\n",
        "* Our X has shape (100 x 4): 100 examples and 4 features\n",
        "* Our W has shape (3 x 4): 3 classes and 4 features. The indices above are reversed because we've taken the transpose of W: the first column of $W^T$ contains the weights for the first class.\n",
        "* The result will have shape (100 x 3): 3 probabilities corresponding to the 3 classes for each of the 100 examples.\n",
        "* $\\phi$ is the softmax function: $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$. It is applied to the rows of $XW^T$.\n",
        "\n",
        "More detailed background [here](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAoIx-nkXhD-"
      },
      "source": [
        "## Softmax Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpah13BcCVXo",
        "outputId": "bbd26804-79e6-40b5-8b98-4e4022c81070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Remember the sigmoid function.\n",
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Our softmax function will normalize over the rows of the input matrix.\n",
        "def softmax(z):\n",
        "  \"\"\"z has shape (m, n): examples, classes\"\"\"\n",
        "  (m, n) = z.shape\n",
        "\n",
        "  # First exponentiate each value\n",
        "  exps = np.exp(z)\n",
        "\n",
        "  # Get the sum of each row and normalize\n",
        "  row_sums = np.sum(exps, axis=1)\n",
        "  for i in range(m):\n",
        "    exps[i,:] /= row_sums[i]\n",
        "\n",
        "  # Fancy/tricky way to do row-wise sums in numpy:\n",
        "  # return np.divide(exps.T, np.sum(exps, axis=1)).T\n",
        "\n",
        "  return exps\n",
        "\n",
        "# Try an example.\n",
        "v = np.array([[1,2,3],\n",
        "              [0,2,4]])\n",
        "print(softmax(v))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09  0.245 0.665]\n",
            " [0.016 0.117 0.867]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLh6VWUfGm7_"
      },
      "source": [
        "## Making Predictions\n",
        "\n",
        "Now, given some initial parameter values (below), compute the model's initial predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGg1Ll4I4jR6",
        "outputId": "4760d3b2-c8cd-48bd-a891-3ae0e32eab83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initial parameter values.\n",
        "# W = np.random.uniform(size=(3,4))\n",
        "W = np.ones((3,4))\n",
        "\n",
        "# Compute predictions.\n",
        "preds = softmax(np.dot(X_train, W.T))\n",
        "print('predictions:\\n', preds[:6])\n",
        "print('label predictions:\\n', np.argmax(preds, axis=1)[:6])\n",
        "print('true labels:\\n', Y_train[:6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions:\n",
            " [[0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]]\n",
            "label predictions:\n",
            " [0 0 0 0 0 0]\n",
            "true labels:\n",
            " [2 1 0 2 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIbpXB4ZHPvO"
      },
      "source": [
        "## Cross-Entropy Loss\n",
        "\n",
        "We'll use the general form of *cross-entropy* loss:\n",
        "\n",
        "\\begin{align}\n",
        "CrossEntropyLoss = \\frac{1}{m} \\sum_i \\sum_j -y_j\\log(\\hat{y_j})\n",
        "\\end{align}\n",
        "\n",
        "In this formula:\n",
        "\n",
        "* $j$ indexes the classes (in our case [0,1,2]) and each $y$ has a dense representation like [0,0,1] which indicates class 2.\n",
        "* *i* indexes over training examples, so we're computing an average loss (as usual)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxpr2OogN70",
        "outputId": "070aeddf-9d9a-4af9-b7dd-fe6bfd06d880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def ce_loss(preds, Y):\n",
        "  \"\"\"\n",
        "    preds are (m,n) m = number of examples, n = number of classes\n",
        "    Y is (m,) -- array of sparse labels\n",
        "    preds[0] = [.1, .1, .8] Y[0] = 2 Y_dense[0] = [0, 0, 1]\n",
        "  \"\"\"\n",
        "  # Get the number of examples\n",
        "  m = Y.shape[0]\n",
        "\n",
        "  # Compute the first sum, the cross-entropy for each example, using\n",
        "  # the rows of the predictions and corresponding labels.\n",
        "  # Note that we need the dense (one-hot) labels.\n",
        "  Y_dense = tf.keras.utils.to_categorical(Y)\n",
        "  # [.1, .1, .8] [0, 0, 1] -> [0, 0, -1*log(.8)] -> -1*log(.8)\n",
        "  cross_entropy_values = - np.sum(Y_dense * np.log(preds), axis=1)\n",
        "\n",
        "  # Here's a more efficient but tricky way to do this:\n",
        "  # cross_entropy_values = -np.log(preds[range(m), Y])\n",
        "\n",
        "  # Sum the per-example cross-entropy values.\n",
        "  loss = np.sum(cross_entropy_values) / m\n",
        "\n",
        "  return loss\n",
        "\n",
        "#print(ce_loss(np.array([.1, .1, .8]), np.array([2])))\n",
        "print(ce_loss(preds, Y_train))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0986122886681093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaRg8b1F93w9"
      },
      "source": [
        "## Computing the Gradient\n",
        "\n",
        "Again, it will turn out that the gradient computation is the same as it was for MSE with linear regression. A happy coincidence.\n",
        "\n",
        "\\begin{align}\n",
        "\\nabla J(W) &= \\frac{1}{m}(h_W(X) - Y)^TX\n",
        "\\end{align}\n",
        "\n",
        "Remember that our parameters $W$ are represented by a matrix of shape (3 x 4): 3 classes and 4 features. The gradient will include a partial derivative for every parameter, and is an average over gradients computed on each training example.\n",
        "\n",
        "Let's review the matrix shapes:\n",
        "\n",
        "* $h_W(X)$ is (100 x 3): 3 probabilities for each example.\n",
        "* $Y$ is (100 x 3): this is the dense (one-hot) version of the labels, matching the shape of the predictions.\n",
        "* $X$ is (100 x 4): 4 features for each example.\n",
        "* The resulting product is (3 x 100)(100 x 4), giving a (3 x 4) output, which matches the shape of our parameters $W$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-j0soKK2qfc",
        "outputId": "c22b3b7c-7eb0-42db-af06-cc5a9d2eb688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# y' = [.1, .2, .7]  y = [0, 0, 1]  diff = y' - y = [.1, .2, -.3]\n",
        "# d1 = [.1, .2, -.3]  x1 = [1, 2, 3, 4]\n",
        "# (3 x 100) (100 x 4) -> (3 x 4)\n",
        "# [ [ .1*1,  .1*2,  .1*3,  .1*4 ]\n",
        "#   [ .2*1,  .2*2,  .2*3,  .2*4 ]\n",
        "#   [-.3*1, -.3*2, -.3*3, -.3*4 ]\n",
        "# ]\n",
        "#\n",
        "# We need the dense version of Y here\n",
        "m = Y_train.shape[0]\n",
        "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
        "diff = preds - Y_train_dense\n",
        "gradient = np.dot(diff.T, X_train) / m\n",
        "print('gradient:\\n', gradient)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient:\n",
            " [[ 0.337 -0.28   0.431  0.411]\n",
            " [-0.042  0.191 -0.089 -0.046]\n",
            " [-0.295  0.09  -0.342 -0.365]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExL4G-pMAXvV",
        "outputId": "7ccdc1a3-9415-4351-de82-ed1b57ef1e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Simplify and just compute the gradient for the first training example.\n",
        "print(diff[0:1].T)\n",
        "print(X_train[0:1])\n",
        "print('gradient:\\n', np.dot(diff[0:1].T, X_train[0:1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.333]\n",
            " [ 0.333]\n",
            " [-0.667]]\n",
            "[[-0.017 -0.543  0.76   1.567]]\n",
            "gradient:\n",
            " [[-0.006 -0.181  0.253  0.522]\n",
            " [-0.006 -0.181  0.253  0.522]\n",
            " [ 0.011  0.362 -0.507 -1.045]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZDyrbc42rcF"
      },
      "source": [
        "## Running Gradient Descent\n",
        "\n",
        "Let's put together the code for a single gradient descent step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl_Nu_wB8ar4",
        "outputId": "9710ad6c-15a9-42e4-9341-9b9990793035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run gradient descent\n",
        "m, n = X.shape  # m = number of examples; n = number of features (including bias)\n",
        "learning_rate = 0.01\n",
        "\n",
        "for _ in range(1000):\n",
        "  preds = softmax(np.dot(X_train, W.T))\n",
        "  loss = ce_loss(preds, Y_train)\n",
        "  gradient = np.dot((preds - tf.keras.utils.to_categorical(Y_train)).T, X_train) / m\n",
        "  W = W - learning_rate * gradient\n",
        "\n",
        "print('labels:\\n', Y_train[:6])\n",
        "print('predictions:\\n', preds[:6])\n",
        "print('loss:', loss)\n",
        "print('gradient:\\n', gradient)\n",
        "print('weights:\\n', W)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:\n",
            " [2 1 0 2 0 2]\n",
            "predictions:\n",
            " [[0.025 0.201 0.774]\n",
            " [0.084 0.673 0.243]\n",
            " [0.99  0.006 0.003]\n",
            " [0.007 0.154 0.838]\n",
            " [0.962 0.032 0.006]\n",
            " [0.014 0.081 0.905]]\n",
            "loss: 0.43657251861677077\n",
            "gradient:\n",
            " [[ 0.012 -0.026  0.026  0.023]\n",
            " [-0.01   0.026 -0.007  0.01 ]\n",
            " [-0.001 -0.    -0.018 -0.033]]\n",
            "weights:\n",
            " [[0.539 1.556 0.295 0.347]\n",
            " [1.08  0.492 1.132 0.922]\n",
            " [1.381 0.951 1.573 1.731]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q72Tu_n_LlO"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj3z7t6-_PZ4",
        "outputId": "59ca136d-0328-4494-9768-39a30a8d8311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions on the test data\n",
        "test_preds = softmax(np.dot(X_test, W.T))\n",
        "test_pred_labels = np.argmax(test_preds, axis=1)\n",
        "print('Accuracy:', np.mean(test_pred_labels == Y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcq8zqKDALmC",
        "outputId": "de78d70c-8b23-41d6-d94e-fa0744a36872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "cf = tf.math.confusion_matrix(Y_test, test_pred_labels)\n",
        "ax = sns.heatmap(cf, annot=True, fmt='.3g', cmap='Blues',\n",
        "                 xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
        "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMsSJ-ZD_12e"
      },
      "source": [
        "## Now with TensorFlow/Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jisaFtGY__KL",
        "outputId": "d934f1b7-2e2c-4f77-ac33-e7e73eab9c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(\n",
        "    units=3,                     # output dim\n",
        "    input_shape=[4],             # input dim\n",
        "    use_bias=False,              # we included the bias in X\n",
        "    activation='softmax',        # apply a sigmoid to the output\n",
        "    kernel_initializer=tf.ones_initializer,  # initialize params to 1\n",
        "))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PQ-RDwXCKVt",
        "outputId": "937f4c88-a85c-4003-cb24-13f7c06201b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# As above, get predictions for the current model first.\n",
        "preds = model.predict(X)\n",
        "\n",
        "# Do a single gradient update.\n",
        "history = model.fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  epochs=100,\n",
        "  batch_size=10,\n",
        "  verbose=0)\n",
        "\n",
        "# Show the loss (before the update) and the new weights.\n",
        "loss = history.history['loss'][0]\n",
        "weights = model.layers[0].get_weights()[0].T\n",
        "print('predictions:\\n', preds[:6])\n",
        "print('loss:', loss)\n",
        "print('W:\\n', weights)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "predictions:\n",
            " [[0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]\n",
            " [0.333 0.333 0.333]]\n",
            "loss: 0.992297887802124\n",
            "W:\n",
            " [[ 0.272  2.881 -0.77  -0.696]\n",
            " [ 1.618 -0.275  2.141  0.16 ]\n",
            " [ 1.204  0.639  2.048  2.972]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAmb6PMCTVET",
        "outputId": "d4f7885e-bb89-4868-8b08-c54d076f5ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(history.history['loss'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.992297887802124, 0.8025609850883484, 0.6757325530052185, 0.6012971997261047, 0.5520737767219543, 0.5170604586601257, 0.49477916955947876, 0.47644829750061035, 0.4634079337120056, 0.452418714761734, 0.44413918256759644, 0.43610242009162903, 0.42947307229042053, 0.4228138029575348, 0.41787415742874146, 0.41321805119514465, 0.408703088760376, 0.4049006700515747, 0.40111109614372253, 0.39859044551849365, 0.39470741152763367, 0.39194750785827637, 0.38938385248184204, 0.38765501976013184, 0.38423338532447815, 0.38197246193885803, 0.38002708554267883, 0.3781062960624695, 0.3759465515613556, 0.3749600350856781, 0.3729705810546875, 0.37111321091651917, 0.369655042886734, 0.36837098002433777, 0.3671342432498932, 0.365773469209671, 0.36499157547950745, 0.36381736397743225, 0.36219605803489685, 0.3613615334033966, 0.3605702221393585, 0.3599521219730377, 0.358480840921402, 0.3578120172023773, 0.3566480576992035, 0.3561931550502777, 0.3551245629787445, 0.3549802005290985, 0.35369908809661865, 0.35304802656173706, 0.3528248071670532, 0.35244929790496826, 0.35166871547698975, 0.3508780002593994, 0.3508646488189697, 0.3496341407299042, 0.3489960730075836, 0.34875965118408203, 0.34814539551734924, 0.34744328260421753, 0.3471892178058624, 0.3466259241104126, 0.3460841476917267, 0.3459753096103668, 0.3455750644207001, 0.3451107144355774, 0.34461671113967896, 0.34424346685409546, 0.3438419997692108, 0.34367144107818604, 0.3436254858970642, 0.34324273467063904, 0.34275832772254944, 0.3425706624984741, 0.34249061346054077, 0.3416541814804077, 0.3414561450481415, 0.3418003022670746, 0.3409843444824219, 0.34075677394866943, 0.34058719873428345, 0.34013092517852783, 0.3400883376598358, 0.3394579291343689, 0.339986652135849, 0.33923956751823425, 0.3395659327507019, 0.33924442529678345, 0.338237464427948, 0.3383134603500366, 0.33816537261009216, 0.3375607430934906, 0.3383040726184845, 0.33717405796051025, 0.33704879879951477, 0.33673447370529175, 0.33695122599601746, 0.3365840017795563, 0.3367391526699066, 0.3368614614009857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuKK7l4fTktl",
        "outputId": "03bf2e34-811c-4401-df23-faeb8a3429ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_preds = model.predict(X_test)\n",
        "test_preds_labels = np.argmax(test_preds, axis=1)\n",
        "accuracy = np.mean(test_preds_labels == Y_test)\n",
        "print(accuracy)\n",
        "model.evaluate(x=X_test, y=Y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "0.9\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2304 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25506189465522766"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBlC_lUmZz9D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
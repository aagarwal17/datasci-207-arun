{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHLcriKWLRe4"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnbWfjivmmpx"
      },
      "source": [
        "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
        "\n",
        "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
        "\n",
        "Additional points may be deducted if these requirements are not met:\n",
        "\n",
        "    \n",
        "* Comment your code;\n",
        "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
        "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsPgo3M0mmpz"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X58hOMTUH-w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poVgAOfAmmp1"
      },
      "source": [
        "### Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ62Zyq0mmp2"
      },
      "outputs": [],
      "source": [
        "def create_1d_data(num_examples, w, b, bound):\n",
        "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
        "\n",
        "  Args:\n",
        "    num_examples: number of examples to generate\n",
        "    w: desired slope\n",
        "    b: desired intercept\n",
        "    bound: lower and upper boundary of the data interval\n",
        "\n",
        "  Returns:\n",
        "    X and Y with shape (num_examples)\n",
        "  \"\"\"\n",
        "  np.random.seed(4)  # consistent random number generation\n",
        "  X = np.arange(num_examples)\n",
        "  deltas = np.random.uniform(low=-bound, high=bound, size=X.shape) # added noise\n",
        "  Y = b + deltas + w * X\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMKof5MUmmp3"
      },
      "source": [
        "---\n",
        "### Step 1: Data ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbCRG2-uUKCT"
      },
      "source": [
        "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
        "\n",
        "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I26yhFNImmp4"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 1:</span> Create data (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIQQpG7ummp5"
      },
      "source": [
        "Create artificial data using the function <span style=\"color:chocolate\">create_1d_data()</span> defined at the top of this notebook. Set the following argument values:\n",
        "- number of examples = 70;\n",
        "- slope (w) = 2;\n",
        "- intercept (b) = 1;\n",
        "- bound = 1.\n",
        "\n",
        "Denote the output by X and Y. Print the shape and the first 10 elements for each object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3VwGlhwmmp5"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "artific_data = create_1d_data(num_examples=70,w=2,b=1,bound=1)\n",
        "artific_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ2CysDBmmp6"
      },
      "source": [
        "---\n",
        "### Step 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y2tL3h_mmp6"
      },
      "source": [
        "Given the simplicity of the data (just one feature in X), our sole task here is to divide the data into training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS-tdQkvmmp7"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 2:</span> Data splits (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMgFBMj7mmp7"
      },
      "source": [
        "Using the <span style=\"color:chocolate\">train_test_split()</span> method available in scikit-learn:\n",
        "1. Split the (X,Y) data into training and test paritions by setting test_size=0.3 and random_state=1234. All the other arguments of the method are set to default values. Name the resulting arrays X_train, X_test, Y_train, Y_test;\n",
        "2. Print the shape of each array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFLrSiCKmmp7"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1:\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(artific_data[0], artific_data[1], test_size=0.3, random_state=1234)\n",
        "\n",
        "# 2:\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"Y_train shape: {Y_train.shape}\")\n",
        "print(f\"Y_test shape: {Y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTjlEudSmmp8"
      },
      "source": [
        "---\n",
        "### Step 3: Exploratory data analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbxD40Xammp8"
      },
      "source": [
        "EDA helps us to gain insights into the distribution and characteristics of the dataset we are dealing with.\n",
        "This understanding is fundamental for making informed decisions regarding:\n",
        "- data cleaning;\n",
        "- feature selection;\n",
        "- model building;\n",
        "- model evaluation, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjHZQdCLmmp9"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 3:</span> Plots (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IZEoFHymmp9"
      },
      "source": [
        "1. Generate a scatter plot displaying the X_train data along the x-axis and the Y_train data along the y-axis, ensuring clear labeling of both axes. Add a title \"Exploratory Data Analysis: Training Data\" and a legend \"observed training data\" to the plot;\n",
        "2. Enhance the plot by incorporating a vertical red line to denote the mean value of X_train. Accompany it with a legend clarifying the meaning of the line and the mean value of X_train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCFyCocPmmp-"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "plt.scatter(X_train, Y_train, label=\"observed training data\", color='black')\n",
        "plt.xlabel('X_train')\n",
        "plt.ylabel('Y_train')\n",
        "plt.title('Exploratory Data Analysis: Training Data')\n",
        "\n",
        "# 2:\n",
        "mean_x = np.mean(X_train)\n",
        "plt.axvline(x=mean_x, color='red', linestyle='--', label=f'Mean of X_train = {mean_x:.2f}')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV4_1y6ummp-"
      },
      "source": [
        "---\n",
        "### Step 4: Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocyaLBVBmmp-"
      },
      "source": [
        "In this section, our objective is to propose models to describe the data generation process. Remember a model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
        "\n",
        "Let's consider two possible models for this data:\n",
        "1. $M_1(x) = 5+x$\n",
        "2. $M_2(x) = 1+2x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6coKbXSpXOz"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 4:</span> Models for data (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55KKb5efmmqA"
      },
      "source": [
        "1. Compute the predictions of models $M_1$ and $M_2$ for the values in X_train. These predictions should be vectors of the same shape as Y_train. Call these predictions M1_hat_train and M2_hat_train. Hint: the \"learned\" parameters are alredy provided to you;\n",
        "2. Plot the prediction lines of these two models overlayed on the observed data (X_train, Y_train). Note: you will generate only one plot. Make sure to include axes names, titles and legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHIY5kNXUIAP"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1.\n",
        "M1_hat_train = 5 + X_train\n",
        "M2_hat_train = 1 + 2 * X_train\n",
        "\n",
        "# 2.\n",
        "plt.scatter(X_train, Y_train, label=\"Observed Training Data\", color='black')\n",
        "plt.plot(X_train, M1_hat_train, label=\"Prediction by M1(x) = 5 + x\", color='blue')\n",
        "plt.plot(X_train, M2_hat_train, label=\"Prediction by M2(x) = 1 + 2x\", color='purple')\n",
        "plt.xlabel('X_train')\n",
        "plt.ylabel('Y_train')\n",
        "plt.title('Model Predictions vs Observed Training Data')\n",
        "mean_x = np.mean(X_train)\n",
        "plt.axvline(x=mean_x, color='red', linestyle='--', label=f'Mean of X_train = {mean_x:.2f}')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fPR19ewmmqB"
      },
      "source": [
        "---\n",
        "### Step 5: Evaluation and Generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH-0soZiWx9x"
      },
      "source": [
        "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textit{MSE} = \\frac{1}{n} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvOOOZypmmqB"
      },
      "source": [
        "How well do our models generalize? The test dataset serves as a proxy for unseen data in real-world applications. By evaluating the model on the test data, you can assess its ability to generalize beyond the training data. This ensures that the model can make accurate predictions on new data it hasn't seen during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AyY2DpxYLI0"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 5:</span> Computing MSE (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn47-DigmmqC"
      },
      "source": [
        "1. Write a function for computing the MSE metric based on the provided definition;\n",
        "2. Utilizing this function, calculate the training data MSE for the two models, $M_1$ and $M_2$.\n",
        "3. Comment on which model fits the training data better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeAfI5mW9sg"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "def MSE(true_values, predicted_values):\n",
        "  \"\"\"Return the MSE between true_values and predicted values.\"\"\"\n",
        "  return (1/len(true_values)) * sum((true_values - predicted_values)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag4L_0_ommqF"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 2.\n",
        "mse_M1 = MSE(Y_train, M1_hat_train)\n",
        "mse_M2 = MSE(Y_train, M2_hat_train)\n",
        "\n",
        "print(f'MSE for M1(x) = 5 + x: {mse_M1}')\n",
        "print(f'MSE for M2(x) = 1 + 2x: {mse_M2}')\n",
        "\n",
        "# 3.\n",
        "if mse_M1 < mse_M2:\n",
        "    print(\"Model M1 fits the training data better (lower MSE).\")\n",
        "else:\n",
        "    print(\"Model M2 fits the training data better (lower MSE).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1psiJ2dmmqF"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 6:</span> Generalization (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT4zRCX8mmqF"
      },
      "source": [
        "1. Compute the predictions of models $M_1$ and $M_2$ for the values in X_test. These predictions should be vectors of the same shape as Y_test. Call these predictions M1_hat_test and M2_hat_test.\n",
        "2. Calculate the test data MSE for the two models, $M_1$ and $M_2$, using the <span style=\"color:chocolate\">MSE()</span> function defined above.\n",
        "3. Does the model you chose in Exercise 5 generalize well?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKq6YUVEmmqG"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "M1_hat_test = 5 + X_test\n",
        "M2_hat_test = 1 + 2 * X_test\n",
        "\n",
        "# 2.\n",
        "MSE_M1_test = MSE(Y_test, M1_hat_test)\n",
        "MSE_M2_test = MSE(Y_test, M2_hat_test)\n",
        "\n",
        "print(f\"MSE for Model M1 on test data: {MSE_M1_test}\")\n",
        "print(f'MSE for Model M1 on train data: {mse_M1}')\n",
        "print(f\"MSE for Model M2 on test data: {MSE_M2_test}\")\n",
        "print(f'MSE for Model M2 on train data {mse_M2}')\n",
        "# 3.\n",
        "# Based on the printed MSE values, the model with the lower MSE on the test data (M2) also performed well on the training data.\n",
        "# In fact, the MSE values are very similar (~0.33 on test and ~0.31 on train). Thus, the model can be considered to generalize well.\n",
        "# While M1 was already stated in exercise 5 to not fit the training data as well as M2, it should be noted that it also generalizes\n",
        "# well with the test data, as the MSE values are again very similar (~1300 on test and ~1358 on train)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAFn-KXummqG"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 7:</span> More features (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7girjH3qmmqG"
      },
      "source": [
        "1. Fit an 8-th degree polynomial to (X_train, Y_train). Call the predictions of this model M3_hat_train. Hint: see <span style=\"color:chocolate\">np.polyfit()</span> for details.\n",
        "2. Plot the prediction lines of the $M_3$ overlayed on the observed data (X_train, Y_train). Note: you will generate only one plot. Make sure to include axes names, titles and legend.\n",
        "3. Calculate the training data MSE for the $M_3$ model using the <span style=\"color:chocolate\">MSE()</span> function defined above.\n",
        "4. Does model $M_3$ do better than your chosen model in Exercise 5 at predicting the labels for new unseen data? Hint: your new unseen data is the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GemhakhmmqG"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "M3 = np.polyfit(X_train, Y_train, deg=8)\n",
        "eight_model = np.poly1d(M3)\n",
        "M3_hat_train = eight_model(X_train)\n",
        "\n",
        "# 2.\n",
        "plt.scatter(X_train, Y_train, label=\"Observed Training Data\", color='black', alpha=0.5)\n",
        "plt.plot(X_train, M3_hat_train, label=f'Model M3 (deg 8)', color='blue', lw=2)\n",
        "plt.xlabel('X_train')\n",
        "plt.ylabel('Y_train')\n",
        "plt.title('Polynomial Fit (Deg 8) on Training Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 3.\n",
        "MSE_M3_train = MSE(Y_train, M3_hat_train)\n",
        "print(f\"MSE for Model M3 on training data: {MSE_M3_train}\")\n",
        "\n",
        "# 4.\n",
        "M3_hat_test = eight_model(X_test)\n",
        "MSE_M3_test = MSE(Y_test, M3_hat_test)\n",
        "print(f\"MSE for Model M3 on test data: {MSE_M3_test}\")\n",
        "print(f\"MSE for Model M2 on test data: {MSE_M2_test}\")\n",
        "print(f'MSE for Model M2 on train data {mse_M2}')\n",
        "\n",
        "if MSE_M3_test < MSE_M2_test:\n",
        "    print(\"Model M3 performs better than our chosen model in Exercise 5 at predicting the labels for new unseen data (lower MSE on test data)\")\n",
        "else:\n",
        "    print(\"Model M2 performs better than our chosen model in Exercise 5 at predicting the labels for new unseen data (lower MSE on test data)\")\n",
        "\n",
        "# By using a degree 8 polynomial, our model fits too well to the training data and fails to generalize to the test data as well as M2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckghdu-OmmqI"
      },
      "source": [
        "----\n",
        "#### <span style=\"color:chocolate\">Additional practice question</span> (not graded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTo89hsimmqI"
      },
      "source": [
        "Would you perform EDA on the test dataset?\n",
        "1. Why or why not?\n",
        "2. Provide a link to a paper/article to support your answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VVk0t4LmmqI"
      },
      "outputs": [],
      "source": [
        "# YOUR ANSWER HERE\n",
        "# 1.\n",
        "\n",
        "# No, I would not perform EDA on the test data because this data is supposed to be unseen data that is only used at time to evaluate the model.\n",
        "# By exploring the test data, we are understanding things about the hidden data that can influence our model training process/decisions\n",
        "# (feature engineering decisions, hyperparameter tuning, etc.). This defeats the purpose of having a test dataset as we can face overfitting\n",
        "# if we were to try to use this model on more newly added data that didn't go through the EDA. This would invalidate the generalizability statement\n",
        "# for our model. Thus, EDA should be done only on the training data, and then evaluated on the test set (allowing us to undeerstand if our preprocessing\n",
        "# decisions were useful as well as the usability of the model).\n",
        "\n",
        "# 2.\n",
        "# The following cite states \"\"\"\n",
        "# The first thing we will want to do with this data is construct a train/test split. Constructing a train test split before EDA and data cleaning can often\n",
        "# be helpful. This allows us to see if our data cleaning and any conclusions we draw from visualizations generalize to new data. This can be done by re-running\n",
        "# the data cleaning and EDA process on the test dataset.\"\"\"\n",
        "# Thus, they are exactly stating what we mention above about isolating the test data from any EDA.\n",
        "# Source: https://ds100.org/sp20/resources/assets/lectures/lec18/TrainTestSplitAndCrossValidation.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsqbVBDZ9rEm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "copyright",
        "xxOhpvdW6TbX",
        "exercise-1-key-1",
        "43ZTSJEc526U",
        "exercise-5-key-1",
        "ubHispCAA_5u",
        "exercise-6-key-1",
        "5p1IvWjfEjqm",
        "exercise-9-key-1"
      ],
      "name": "01 Introduction.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
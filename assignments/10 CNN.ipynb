{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Objectives``\n",
    "1. Implement a CNN to detect diabetic retinopathy (DR) from retina images taken using fundus photography under a variety of imaging conditions.\n",
    "2. Improve generalization performance and reduce overfitting using **image transformation** and **data augmentation** techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Motivation``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diabetic retinopathy (DR) is an eye condition that  affects blood vessels in the retina. It can cause vision loss and blindness in people who have diabetes. Screening for DR allows earlier and more effective treatment options for millions of people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Data``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will use a small dataset of retina images (`Download` links: [images](https://drive.google.com/drive/folders/1sdfUC64Un1iwuiHEehcbijxB54OhU_nd?usp=sharing) and [labels](https://drive.google.com/drive/folders/1MOlSJBZg7L1HtG5vHPt77ighRvQaGfDg?usp=sharing)). You will **build** and **train** a **CNN model** to predict whether or not to refer a patient for DR treatment using binarized severity of DR in patients: no referral if {No DR, mild} and referral if {moderate, severe, and proliferate DR}.\n",
    "\n",
    "\n",
    "<u>Note</u>: the original dataset is hosted by Kaggle [[Source]](https://www.kaggle.com/c/aptos2019-blindness-detection/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and make sure to replace IMAGE_PATH and LABEL_PATH with the path to the directories where you saved the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(2)\n",
    "%matplotlib inline\n",
    "\n",
    "# FILL IN CODE HERE #\n",
    "IMAGE_PATH = './data/DiabeticRetinopathy/images/' # replace with your path\n",
    "LABEL_PATH = './data/DiabeticRetinopathy/labels/' # replace with your path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you may ask yourself what the best model that fits this data is. First, you will want to read through the data description in Kaggle (see the link to the original dataset above). Understanding what you are working with challenges you to write preprocessing code that uncovers your data's most helpful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <span style=\"color:chocolate\"> Exercise 1 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data description from Kaggle and list (a) the source of images and (b) the labeling procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Written answer*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the 2D images and their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``labels``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels: (200, 2)\n",
      "Unique diagnosis codes: [0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  000c1434d8d7          2\n",
       "1  0024cdab0c1e          1\n",
       "2  0083ee8054ee          4\n",
       "3  00a8624548a9          2\n",
       "4  00b74780d31d          2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\n",
    "    LABEL_PATH + 'labels.csv'\n",
    ")\n",
    "\n",
    "print('Shape of labels:', labels.shape)\n",
    "print('Unique diagnosis codes:', np.sort(labels.diagnosis.unique()))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 200 training images corrresponding to 5 different diabetic retinopathy (DR) diagnosis codes: \n",
    "\n",
    "* No DR (0)\n",
    "* mild (1)\n",
    "* moderate (2)\n",
    "* severe (3)\n",
    "* proliferate DR (4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``images``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for idx, img in enumerate(os.listdir(IMAGE_PATH)):\n",
    "    img = load_img(\n",
    "    IMAGE_PATH + img)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 2 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram for the five classes of DR. Are the classes balanced?\n",
    "\n",
    "\n",
    "Note: It's acceptable to plot the distribution of classes before splitting your data into training, validation, and test sets. Doing so does not compromise the \"blindness\" of the test data. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on class balance: [YOUR ANSWER HERE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 3 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print 8 images from the data. What can you say about the size, focus/orientation of these images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the size, focus/orientation of the 8 images: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will correct for class imbalance. Note that imbalanced data is common in healthcare, and it happens because some diseases are rare. The presence of imbalanced data hampers the detection of rare events as most classification methods implicitly assume a similar occurrence of classes and are designed to maximize the overall classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will correct for class imbalance in two ways:\n",
    "\n",
    "  * First, we will binarize the DR diagnosis as follows:\n",
    "     - 'no refer' are {No DR, mild}\n",
    "     - 'refer' are {Moderate, Severe, Proliferate}\n",
    "\n",
    "\n",
    "  * Second, we'll only take 80 random samples from the 'no refer' class and 80 from the 'refer' class.\n",
    "\n",
    "It is a crude method to deal with imbalanced data, but it will be good enough for this homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "no_refer = labels[labels.diagnosis.isin((0,1))]\n",
    "refer = labels[labels.diagnosis.isin((2,3,4))]\n",
    "\n",
    "# randomly draw 80 images from each classes\n",
    "temp_no_refer = list(np.random.choice(\n",
    "    no_refer.id_code,\n",
    "    size=80,\n",
    "    replace=False\n",
    "))\n",
    "\n",
    "temp_refer = list(np.random.choice(\n",
    "    refer.id_code,\n",
    "    size=80,\n",
    "    replace=False\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the ``preprocess_data_part1()`` function defined below to generate lists of images and labels (images_mini and y_mini) based on the values in the temp_no_refer and temp_refer lists. Note that the size of the image is set to (224, 224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_part1(IMAGE_PATH, LABEL_PATH, temp_no_refer, temp_refer):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    LABEL_PATH (str): path to directory with labels.\n",
    "    temp_no_refer (str): list of labels for the no refer category\n",
    "    temp_refer (str): list of labels for the refer category\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 224, 224, 3)\n",
    "    y_mini (np.ndarray): Labels of shape (N,)    \n",
    "    \"\"\"\n",
    "    y_mini = []\n",
    "    images_mini = []\n",
    "\n",
    "    # create lists of images and labels `images_mini` and `y_mini` \n",
    "    # based on temp_no_refer and temp_refer selections\n",
    "    for idx, img in enumerate(os.listdir(IMAGE_PATH)):\n",
    "        # read labels\n",
    "        if img.split('.')[0] in temp_no_refer:\n",
    "                y_mini.append(0)\n",
    "        elif img.split('.')[0] in temp_refer:\n",
    "                y_mini.append(1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # read image\n",
    "        img = load_img(\n",
    "            IMAGE_PATH + img,\n",
    "            target_size=(224, 224)\n",
    "        )\n",
    "        \n",
    "        # transform image to array\n",
    "        img = img_to_array(img)\n",
    "\n",
    "        # append to images\n",
    "        images_mini.append(img)\n",
    "\n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(images_mini)\n",
    "    y_mini = np.array(y_mini).flatten() \n",
    "    \n",
    "    return images_mini, y_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_mini shape (160, 224, 224, 3)\n",
      "y_mini shape (160,)\n"
     ]
    }
   ],
   "source": [
    "# generate images and labels based on preprocess_data_part1() function\n",
    "images_mini, y_mini = preprocess_data_part1(\n",
    "    IMAGE_PATH, LABEL_PATH, temp_no_refer, temp_refer\n",
    ")\n",
    "\n",
    "print(f\"images_mini shape {images_mini.shape}\")\n",
    "print(f\"y_mini shape {y_mini.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 4 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, validation, and test data. Implement the `preprocess_data_part2()` function according to the following guidelines:\n",
    "\n",
    "1. shuffle images and labels before splitting the data\n",
    "\n",
    "2. use a (0.6,0.2,0.2)train/validation/test set split\n",
    "\n",
    "3. perform image transformation and augmentation, as follows:\n",
    "    * Applied on training set only:\n",
    "         - create additional copies (augmentations) of the training images by flipping left right each image (Hint: use the method available in the tf.image module).\n",
    "         - concatenate the augmented images to the original training images. Note that the train set should be double in size after data augmentation, i.e., 192 images and labels.\n",
    "    * Applied on training, validation, and test sets:\n",
    "        - rescale images by dividing each pixel by 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for doing image augmentation: The quantity and diversity of data gathered significantly impact the results of a CNN model. One can use augmentations to artificially inflate the training dataset by warping the original data so that their label does not change. These augmentations can significantly improve learning results without collecting new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_part2(images, labels, splits):\n",
    "    \"\"\" Split data into train, validation and test sets; apply transformaions and augmentations\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    images  (np.ndarray): Images of shape (N, 224, 224, 3)\n",
    "    labels (np.ndarray): Labels of shape (N,)   \n",
    "    splits (tuple): 3 values summing to 1 defining split of train, validation and test sets\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 224, 224, 3)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_val (np.ndarray): Val images of shape (N_val, 224, 224, 3)\n",
    "    y_val (np.ndarray): Val labels of shape (N_val,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 224, 224, 3)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: Each time you run this cell, you'll re-shuffle the data. The ordering will be the same due to the random seed generator \n",
    "    tf.random.set_seed(1234)\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    # shuffle data\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    # create data splits (training, val, and test sets)\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    # image augmentation (random flip) on training data\n",
    "    X_train_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "    # concatenate original X_train and augmented X_train_augm data\n",
    "    X_train = '' # FILL IN CODE HERE #\n",
    "\n",
    "    # concatenate y_train (note the label is preserved)\n",
    "    y_train_augm = y_train\n",
    "    y_train = tf.concat([y_train, y_train_augm],axis=0)\n",
    "\n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
    "    X_train = tf.gather(X_train, shuffle).numpy() # transform X back to numpy array instead of tensor\n",
    "    y_train = tf.gather(y_train, shuffle).numpy() # transform y back to numpy array instead of tensor\n",
    "\n",
    "    # rescale training, val, and test images by dividing each pixel by 255.0 \n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (192, 224, 224, 3)\n",
      "y_train shape (192,)\n",
      "X_val shape (32, 224, 224, 3)\n",
      "y_val shape (32,)\n",
      "X_test shape (32, 224, 224, 3)\n",
      "y_test shape (32,)\n"
     ]
    }
   ],
   "source": [
    "# define splits\n",
    "split = (0.6, 0.2, 0.2)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data_part2(\n",
    "    images_mini,\n",
    "    y_mini,\n",
    "    split\n",
    ")\n",
    "\n",
    "print(f\"X_train shape {X_train.shape}\")\n",
    "print(f\"y_train shape {y_train.shape}\")\n",
    "print(f\"X_val shape {X_val.shape}\")\n",
    "print(f\"y_val shape {y_val.shape}\")\n",
    "print(f\"X_test shape {X_test.shape}\")\n",
    "print(f\"y_test shape {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 5 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to build and train a CNN model to refer patients to doctors based on the severity of DR seen in these images. You are interested in exploring binary classification of 'no refer' and 'refer'.\n",
    "\n",
    "Implement a CNN classifier according to the following guidelines (let's call this *model_tf*):\n",
    "\n",
    "1. Implement this model using the TF Keras API.\n",
    "1. The model receives input images of size 224 x 224 x 3 (that is, the images have three color channels)\n",
    "2. The input data goes through one convolutional layer that has the following specifications:\n",
    "    - filters = 12\n",
    "    - kernel_size = (4 x 4)\n",
    "    - strides = (1, 1)\n",
    "    - padding = 'same'\n",
    "    - data_format = 'channels_last'\n",
    "    - name = 'conv_1'\n",
    "    - activation = 'relu'\n",
    "3. The convolutional layer is followed by a max-pooling layer with pool_size = (2,2). Note: this will reduce the size of the feature maps.\n",
    "4. The max-pooling layer is followed by a dropout layer with rate = 0.3.\n",
    "5. The dropout layer is followed by a flattening layer.\n",
    "6. The last layer of the model is the classification head.\n",
    "7. Build and compile the model using the Adam optimizer and learning_rate = 0.1. Print summary of the model.\n",
    "8. Train the model on (X_train, y_train) data for 20 epochs. Add early stopping (Hint: pass the early_stopping implementation below to the fit() method as \"callbacks=[early_stopping]\").\n",
    "9. How many parameters does the model have?\n",
    "10. Generate a plot (for the training and validation data) with the loss values on the y-axis and the epoch number on the x-axis for visualization. Make sure to include axes name and title. Hint: check what the tf.keras.Model.fit() method returns.\n",
    "11. Evaluate the accuracy of the model on (X_train, y_train) and (X_val, y_val) data. Comment on model performance on training vs. validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an instance of the early_stopping class\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "monitor='accuracy', \n",
    "verbose=1,\n",
    "patience=5,\n",
    "mode='max',\n",
    "restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# initialize model\n",
    "model_tf = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add max pooling layer \n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add dropout layer\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add a flattening layer\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add the classification layer\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# build and compile model\n",
    "model_tf.build(input_shape=(None, 224, 224, 3))\n",
    "model_tf.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# print model_tf summary\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# train model_tf on (X_train, y_train) data\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# plot loss curves\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# evaluate the accuracy of model_tf on (X_train, y_train) and (X_val, y_val)\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parameters does *model_tf* have? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on *model_tf* accuracy on training vs. validation data: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 6 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fine-tune the number of hidden layers and the hyperparameters of *model_tf* to determine the setup that yields the most optimal generalization performance. Feel free to explore various model configurations/hyperparameter values.\n",
    "\n",
    "2. How many parameters does your fine-tuned model have?\n",
    "\n",
    "3. Evaluate the accuracy of the fine-tuned model on (X_train, y_train) and (X_val, y_val) data. Comment on model performance on training vs. validation datasets.  Is there an improvement compared to the non-fine-tuned version of the model (Exercise 5)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parameters does your fine-tuned model have? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on accuracy of the fine-tuned model on training vs. validation performance. Is there an improvement over the non-fine-tuned version? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 7 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use the test data to evaluate the performance (accuracy) of your fine-tuned model on unseen data. Does your model generalize well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does your model generalize well? [YOUR ANSWER HERE]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

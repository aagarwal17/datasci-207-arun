{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKsRDH5ZUdfasdv"
      },
      "source": [
        "# Assignment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjhYS51aLOt"
      },
      "source": [
        "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
        "\n",
        "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
        "\n",
        "Additional points may be deducted if these requirements are not met:\n",
        "\n",
        "    \n",
        "* Comment your code;\n",
        "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
        "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5F4UmEuaLOu"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smVKD1zDaLOu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns  # for nicer plots\n",
        "sns.set(style=\"darkgrid\")  # default style\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import keras_tuner as kt\n",
        "from keras_tuner import HyperParameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm2HJBVFaLOw"
      },
      "source": [
        "This lab continues our study of linear regression. You'll train your first models with Tensorflow, using a real dataset to predict car prices from their features. Note that Tensorflow is a rapidly changing library. This means you'll often see warnings about deprecations. You can ignore the warnings in our labs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Xt7Z1laLOw"
      },
      "source": [
        "---\n",
        "### Step 1: Data ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHLcriKWLRe4"
      },
      "source": [
        "You'll use the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile)  from 1985 Ward's Automotive Yearbook that is part of the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_auto_data_set_code"
      },
      "outputs": [],
      "source": [
        "# Provide the names for the feature columns since the CSV file with the data\n",
        "# does not have a header row.\n",
        "cols = ['losses', 'make', 'fuel-type', 'aspiration', 'num-doors',\n",
        "        'body-style', 'drive-wheels', 'engine-location', 'wheel-base',\n",
        "        'length', 'width', 'height', 'weight', 'engine-type', 'num-cylinders',\n",
        "        'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio',\n",
        "        'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price','symboling']\n",
        "\n",
        "# Load the data from a CSV file into a pandas dataframe. Remember that each row\n",
        "# is an example and each column in a feature.\n",
        "car_data_init = pd.read_csv(\n",
        "    'https://github.com/aagarwal17/datasci-207-arun/blob/main/assignments/cars_data.csv?raw=true',\n",
        "    sep=',', names=cols, skiprows = 1, encoding='latin-1')\n",
        "\n",
        "# Display top five rows\n",
        "print('Shape of data:', car_data_init.shape)\n",
        "car_data_init.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgDbiUOaaLOx"
      },
      "source": [
        "---\n",
        "### Step 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MwN2jcXaLOy"
      },
      "source": [
        "This step is essential for preparing the data in a format that is suitable for ML algorithms. It helps ensure data quality and improvements in model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzQ7DpYDaLOy"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 1:</span> Column selection (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMpTNjlaLOz"
      },
      "source": [
        "To keep things simple, you will:\n",
        "\n",
        "1. Retain only the following columns: ['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']. Name the new dataframe *car_data*.\n",
        "2. Display the data type of each column;\n",
        "3. Convert the data type of each columns to numeric. Coerce missing values to NaN. Hint: use <span style=\"color:chocolate\">pd.to_numeric()</span> method;\n",
        "4. Display the data type of each column after the transformation performed at point 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHlvyWDiaLOz"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1.\n",
        "car_data = car_data_init[['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']]\n",
        "\n",
        "# 2\n",
        "print(\"Data types of each column:\")\n",
        "print(car_data.dtypes)\n",
        "\n",
        "# 3.\n",
        "for column in car_data.columns:\n",
        "    car_data[column] = pd.to_numeric(car_data[column], errors='coerce')\n",
        "\n",
        "# 4.\n",
        "print(\"Data types after conversion:\")\n",
        "print(car_data.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs7cTQByaLO0"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 2:</span> Example (row) selection (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPG41xSxaLO0"
      },
      "source": [
        "To keep things simple again, you will:\n",
        "\n",
        "1. Print the shape of the car_data;\n",
        "\n",
        "2. Remove examples (rows) that have missing value(s). Note that in doing so, you will overwrite the car_data dataset. You should end up with 199 examples after this cleaning.\n",
        "\n",
        "3. Print the shape of the car_data again.\n",
        "\n",
        "It's important to acknowledge that there are multiple approaches to handling missing features, and simply discarding examples with any missing feature, though straightforward, may not be the most optimal solution. However, for the sake of simplicity, you will implement this strategy in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBRqRYa8aLO0"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "print(\"Shape of car_data before cleaning:\", car_data.shape)\n",
        "\n",
        "# 2.\n",
        "car_data = car_data.dropna()\n",
        "\n",
        "# 3.\n",
        "print(\"Shape of car_data after cleaning:\", car_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq-j4-h1aLO0"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 3:</span> Data shuffling (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1lciaZLaLO1"
      },
      "source": [
        "Since you'll be using Batch Gradient Descent (BGD) for training, it is important that **each batch is a random sample of the data** so that the gradient computed is representative. Note that the original data (above) appears sorted by *make* in alphabetic order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA6BDvi1aLO1"
      },
      "source": [
        "Using NumPy and Pandas methods:\n",
        "\n",
        "1. Create a list of indices corresponding to the rows in the car_data dataset. Call this list *indices*. Print this list;\n",
        "\n",
        "2. Shuffle *indices* using the <span style=\"color:chocolate\">np.random.permutation()</span> method. Call the resulting array *shuffled_indices*. Print this array;\n",
        "    \n",
        "3. Use the method <span style=\"color:chocolate\">dataframe.reindex()</span> to change the ordering of the car_data dataset based on the order in the *shuffled_indices* array. Note that in doing so, you will overwrite the original dataset. Print the top 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcM8-ma-aLO1"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "# 1.\n",
        "indices = list(car_data.index)\n",
        "print(\"Original indices:\", indices)\n",
        "\n",
        "# 2.\n",
        "shuffled_indices = np.random.permutation(indices)\n",
        "print(\"Shuffled indices:\", shuffled_indices)\n",
        "\n",
        "# 3.\n",
        "car_data = car_data.reindex(shuffled_indices)\n",
        "print(\"Top 5 rows after shuffling:\")\n",
        "print(car_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-BhUmjBaLO1"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 4:</span> Define outcome and features (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbdNhI4FaLO2"
      },
      "source": [
        "Create two dataframes as follows:\n",
        "\n",
        "1. The first dataframe contains our outcome of interest: ['price']. Note, this is what we are aiming to predict. Name this dataframe Y. Print shape of Y.\n",
        "2. The second dataframe contains our features of interest: ['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']. Name this dataframe X. Print shape of X.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30d7L53MaLO2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "Y = car_data[['price']]\n",
        "print(\"Shape of Y:\", Y.shape)\n",
        "\n",
        "# 2.\n",
        "X = car_data[['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']]\n",
        "print(\"Shape of X:\", X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFi6B-dsaLO2"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 5:</span> Data splits (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQnRfmFbaLO2"
      },
      "source": [
        "Using the <span style=\"color:chocolate\">train_test_split()</span> method available in scikit-learn:\n",
        "1. Partition the (X, Y) data into training, validation, and test sets using a splitting rule of [60%, 20%, 20%], with a random state set to 1234. Name the resulting dataframes as follows: X_train, X_val, X_test, Y_train, Y_val, Y_test. Hint: To create these three partitions you will utilize the train_test_split() method twice (all the other arguments of the method are set to default values.). You should obtain [119, 40, 40] examples for training, validation, and test, respectively.\n",
        "2. Print the shape of each dataframe.\n",
        "\n",
        "Note: The validation set is crucial for evaluating different hyperparameter configurations and selecting those that yield optimal model performance. This approach avoids utilizing the test dataset during model training, as it is assumed to be \"unknown\" at that stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVPybPKFaLO3"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1.\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.4, random_state=1234)\n",
        "\n",
        "# 2.\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=1234)\n",
        "\n",
        "# 3.\n",
        "print(\"Shapes of datasets:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_val:\", X_val.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"Y_val:\", Y_val.shape)\n",
        "print(\"Y_test:\", Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxm2aa4laLO3"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 6:</span> Data standardization (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12wHqzKMaLO3"
      },
      "source": [
        "With this concept in mind, complete the following tasks:\n",
        "\n",
        "1. Output the quantile values (0.25, 0.5, 0.75, 0.95) for all features in the X_train dataset. Are these values uniformly scaled across features?\n",
        "\n",
        "2. Standardize all features in X_train, X_val, and X_test. Label the resulting dataframes as X_train_std, X_val_std, and X_test_std, respectively. Hint: standardize the validation and test data using the mean and standard deviation computed from the training data. Why?\n",
        "\n",
        "3. Similar to point 2. but now standardize the outcome variable. Label the resulting dataframes as Y_train_std, Y_val_std, and Y_test_std."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_SSh8PXaLO3"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1.\n",
        "quantiles = X_train.quantile([0.25, 0.5, 0.75, 0.95])\n",
        "print(\"Quantile values for X_train:\")\n",
        "print(quantiles)\n",
        "print(\"Q1: By examining the quantiles, we see the values are not uniformly scaled across features\")\n",
        "\n",
        "# 2.\n",
        "X_mean = X_train.mean()\n",
        "X_std = X_train.std()\n",
        "\n",
        "X_train_std = (X_train - X_mean) / X_std\n",
        "X_val_std = (X_val - X_mean) / X_std\n",
        "X_test_std = (X_test - X_mean) / X_std\n",
        "print(\"Q2: We standardize the validation and test data using the mean and standard deviation computed from the training data to prevent data leakage. That is, we want to keep the validation and test sets unseen by the model during training to avoid overfitting.\")\n",
        "\n",
        "# 3.\n",
        "Y_mean = Y_train.mean()\n",
        "Y_std = Y_train.std()\n",
        "\n",
        "Y_train_std = (Y_train - Y_mean) / Y_std\n",
        "Y_val_std = (Y_val - Y_mean) / Y_std\n",
        "Y_test_std = (Y_test - Y_mean) / Y_std\n",
        "print(\"We standardize the outcome variable so that the model puts the target variable on the same scale as the features, preventing bias.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3L_O3EyaLO3"
      },
      "source": [
        "---\n",
        "### Step 3: Exploratory data analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChRhKbdnaLO3"
      },
      "source": [
        "EDA plays a very important role in ML. The goal here is to develop a good understanding of our training dataset, identify any data quality issues, understand patterns and relationships, which in turn, aids in subsequent modeling and interpretations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIPtTcc6aLO4"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 7:</span> Scatterplot matrix (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWl0Bq3yaLO4"
      },
      "source": [
        "In this exercise you will use some simple yet useful techniques to visualize the distribution of the data.\n",
        "\n",
        "Let's start with:\n",
        "\n",
        "1. A scatterplot matrix to visualize the pair-wise correlations between different features and outcome in the (X_train_std, Y_train_std) data. You will use the <span style=\"color:chocolate\">sns.pairplot()</span> method from the seaborn library imported at the top of the notebook;\n",
        "2. Is any of the variables in the data normally distributed? Is it necessary for the explanatory or target variable to be normally distributed in order to train a ML model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyg9gMdsaLO5"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1.\n",
        "data = pd.concat([X_train_std, Y_train_std], axis=1)\n",
        "sns.pairplot(data)\n",
        "plt.show()\n",
        "\n",
        "# 2.\n",
        "print(\"Q2a. We determine if any of the variables in the data are normally distributed by looking at the plots along the diagonal. \\nWe see that peak_rpm and highway-mpg look semi-normal. \\nOtherwise, the other features are non-normally distributed (do not show a bell-shaped, symmetric distribution).\")\n",
        "print(\"Q2b. No, it is not necessary for the explanatory or target variable variables to be normally distributed to train a ML model. \\nWhile some models like linear regression may perform better when the variables are normally distributed, the explanatory or target variable does not need to be normally distributed for this. \\nWe state in the module demo that 'ML prediction does not require the outcome and feature variables to be normally distributed! \\nThis is a requirement for inference and hypothesis testing but not for predictive analysis'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PyAkct6aLO5"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 8:</span> Correlation matrix (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L7mtYasaLO5"
      },
      "source": [
        "In this exercise you will:\n",
        "\n",
        "1. Plot a correlation matrix in the form of a heatmap to visualize the linear relationships between different features and outcome in the (X_train_std, Y_train_std) data. Hint: this example here is very useful: https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
        "    \n",
        "2. Answer the following questions:\n",
        " - Which two features are likely to be most redundant?\n",
        " - Which feature is likely to be least useful for predicting price?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3jNFEVxaLO5"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "correlation_matrix = pd.concat([X_train_std, Y_train_std], axis=1).corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# 2.\n",
        "redundant_features = correlation_matrix.abs().unstack().sort_values(ascending=False)\n",
        "redundant_pairs = redundant_features[(redundant_features < 1) & (redundant_features > 0.8) | (redundant_features > -1) & (redundant_features < -0.8)]\n",
        "print(f\"Q2a. The most redundant features are those with a correlation close to 1 or -1 (aka highly correlated). \\nBy my calculation above or by examining the heatmap, we see the top pairs/most redundant features are\\n: {redundant_pairs.head(4)} \\n(Note: a heatmap includes every value twice unless I put a mask on it to just show the needed triangle, so the top 4 includes each pairing twice.)\")\n",
        "\n",
        "least_useful_feature = correlation_matrix['price'].abs().idxmin()\n",
        "print(f\"Q2b. The feature with the lowest correlation to the target variable (price) is likely to be least useful. \\nBy examining the heatmap or using our calculation below, we find the least useful feature to be: {least_useful_feature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQOBrAD-aLO6"
      },
      "source": [
        "---\n",
        "### Step 4: Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk6AGrBIaLO6"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 9:</span> Baseline model (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imjQKhA_aLO7"
      },
      "source": [
        "Let's start by evaluating a baseline model. Precisely, you'll use the average price of cars in the training set as our baseline model -- that is, the baseline always predicts the average price regardless of the input.\n",
        "\n",
        "1. Implement this baseline using the Y_train_std data and print the average price. Note: You can revert the price variable to the original scale for interpretation purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhpH9nztaLO7"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# 1.\n",
        "mean_price_std = Y_train_std.mean()\n",
        "mean_price = (mean_price_std * Y_std) + Y_mean\n",
        "print(f\"Average price in the training set (original scale): ${mean_price.values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBXeXWygp4T"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 10:</span> Improvement over Baseline with TensorFlow (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDsxLnljlp0C"
      },
      "source": [
        "Let's train a linear regression model much like we did in the previous assignment, but this time using TensorFlow.\n",
        "\n",
        "1. Fill in the <span style=\"color:green\">NotImplemented</span> parts of the build_model() function below by following the instructions provided as comments. Hint: refer to Demo 3 in [bCourses/Modules/Live Session Demos](https://bcourses.berkeley.edu/courses/1534588/files/88733489?module_item_id=17073646) for an example.\n",
        "2. Build and compile a model using the build_model() function and the (X_train_std, Y_train_std) data. Set learning_rate = 0.0001. Call the resulting object *model_tf*.\n",
        "3. Train *model_tf* using the (X_train_std, Y_train_std) data. Set num_epochs = 5. Pass the (X_val_std, Y_val_std) data for validation. Hint: see the documentation behind the [tf.keras.Model.fit()](https://bcourses.berkeley.edu/courses/1534588/files/88733489?module_item_id=17073646) method.\n",
        "3. Generate a plot with the loss values on the y-axis and the epoch number on the x-axis for visualization. Make sure to include axes name and title. Hint: check what the [tf.keras.Model.fit()](https://bcourses.berkeley.edu/courses/1534588/files/88733489?module_item_id=17073646) method returns.\n",
        "\n",
        "More notes on point 1: the idea is to build a *computational graph* for linear regression, and then send data through it. There are many ways to build graphs, but [TenforFlow Keras API](https://www.tensorflow.org/api_docs/python/tf/keras) is recommended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfdRzjk-RgpG"
      },
      "outputs": [],
      "source": [
        "def build_model(num_features, learning_rate):\n",
        "  \"\"\"Build a TF linear regression model using Keras.\n",
        "\n",
        "  Args:\n",
        "    num_features: The number of input features.\n",
        "    learning_rate: The desired learning rate for SGD.\n",
        "\n",
        "  Returns:\n",
        "    model: A tf.keras model (graph).\n",
        "  \"\"\"\n",
        "  # This is not strictly necessary, but each time you build a model, TF adds\n",
        "  # new nodes (rather than overwriting), so the colab session can end up\n",
        "  # storing lots of copies of the graph when you only care about the most\n",
        "  # recent. Also, as there is some randomness built into training with SGD,\n",
        "  # setting a random seed ensures that results are the same on each identical\n",
        "  # training run.\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(0)\n",
        "\n",
        "  # Build a model using keras.Sequential. While this is intended for neural\n",
        "  # networks (which may have multiple layers), we want just a single layer for\n",
        "  # linear regression.\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(\n",
        "      units=1,        # output dim\n",
        "      input_shape=(num_features,),  # input dim\n",
        "      use_bias=True,               # use a bias (intercept) param\n",
        "      kernel_initializer=tf.ones_initializer,  # initialize params to 1\n",
        "      bias_initializer=tf.ones_initializer,    # initialize bias to 1\n",
        "  ))\n",
        "\n",
        "  # We need to choose an optimizer. We'll use GD, which is actually mini-batch GD\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "  # Finally, compile the model. This finalizes the graph for training.\n",
        "  # We specify the MSE loss and the optimizer above\n",
        "  model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "    )\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvqK58CtaLO8"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "# 2. Build and compile model\n",
        "# YOUR CODE HERE\n",
        "learning_rate = 0.0001\n",
        "model_tf = build_model(X_train_std.shape[1], learning_rate)\n",
        "\n",
        "# 3. Fit the model\n",
        "# YOUR CODE HERE\n",
        "history = model_tf.fit(X_train_std, Y_train_std, epochs=5, validation_data=(X_val_std, Y_val_std))\n",
        "\n",
        "# 4.\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuFPHBUhaLO8"
      },
      "source": [
        "---\n",
        "### Step 5: Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqKkGTIHaLO9"
      },
      "source": [
        "Hyperparameter tuning is a crucial step in optimizing ML models. It involves systematically adjusting hyperparameters such as learning rate, number of epochs, and optimizer to find the model configuration that leads to the best generalization performance.\n",
        "\n",
        "This tuning process is typically conducted by monitoring the model's performance on the validation vs. training set. It's important to note that using the test set for hyperparameter tuning can compromise the integrity of the evaluation process by violating the assumption of \"blindness\" of the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDMTleb-aLO9"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 11:</span> Hyperparameter tuning (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cfyh7uEaLO9"
      },
      "source": [
        "1. Fine-tune the **learning rate** and **number of epochs** hyperparameters of *model_tf* to determine the setup that yields the most optimal generalization performance. Feel free to explore various values for these hyperparameters. Hint: you can manually test different hyperparameter values or you can use the [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner). If you decide to work with the Keras Tuner, define a new model building function named <span style=\"color:chocolate\">build_model_tuner()</span>.\n",
        "\n",
        "After identifying your preferred model configuration, print the following information:\n",
        "\n",
        "2. The learned parameters of the tuned model (this should include the bias term). Hint: use  <span style=\"color:chocolate\">[model_name].layers[0].get_weights()</span>.\n",
        "3. The loss at the final epoch on both the training and validation datasets;\n",
        "4. The difference between the last-epoch loss observed on the training and validation datasets.\n",
        "\n",
        "\n",
        "Please note that we will consider 'optimal model configuration' any last-epoch training loss that is below 0.31 and any last epoch validation loss that is below 0.48."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "pdIHAsLHyLK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFNEbbBBaLO9"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "# YOUR CODE HERE\n",
        "from keras_tuner import HyperModel, Hyperband\n",
        "\n",
        "# 1. Defining the model for tuning using Keras Tuner\n",
        "def build_model_tuner(hp):\n",
        "    \"\"\"Build a TF linear regression model using Keras for hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "        num_features: The number of input features.\n",
        "        learning_rate: The desired learning rate for SGD.\n",
        "\n",
        "    Returns:\n",
        "        model: A tf.keras model (graph).\n",
        "    \"\"\"\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.random.set_seed(0)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        input_shape=(X_train_std.shape[1],),\n",
        "        use_bias=True,\n",
        "        kernel_initializer=tf.ones_initializer,\n",
        "        bias_initializer=tf.ones_initializer,\n",
        "    ))\n",
        "\n",
        "    # Hyperparameters for tuning\n",
        "    learning_rate = hp.Choice('learning_rate', values=[1e-1,1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 1e-5])\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Set up the hyperparameter tuning using Keras Tuner\n",
        "tuner = Hyperband(\n",
        "    build_model_tuner,\n",
        "    objective='val_loss',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='hyperparameter_tuning',\n",
        "    project_name='linear_regression_tuning'\n",
        ")\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train_std, Y_train_std, epochs=50, validation_data=(X_val_std, Y_val_std), callbacks=[stop_early], verbose=0)\n",
        "\n",
        "# Getting the best model and hyperparameters\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Printing the best hyperparameters\n",
        "print(\"Best hyperparameters:\", best_hyperparameters.values)\n",
        "\n",
        "# Finding Ideal number of epochs\n",
        "best_model = tuner.hypermodel.build(best_hyperparameters)\n",
        "history = best_model.fit(X_train_std, Y_train_std, epochs=50, validation_data=(X_val_std, Y_val_std), verbose=1)\n",
        "val_loss_per_epoch = history.history['val_loss']\n",
        "best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "# Retraining model with best hyperparams:\n",
        "best_model = tuner.hypermodel.build(best_hyperparameters)\n",
        "history = best_model.fit(X_train_std, Y_train_std, epochs=best_epoch, validation_data=(X_val_std, Y_val_std), verbose=1)\n",
        "\n",
        "# 2. Getting learned weights and bias from the best model\n",
        "weights, bias = best_model.layers[0].get_weights()\n",
        "print(\"Learned Parameters (Weights):\", weights)\n",
        "print(\"Learned Bias Term:\", bias)\n",
        "\n",
        "# 3. Printing the loss at the final epoch for both training and validation datasets\n",
        "final_train_loss = best_model.history.history['loss'][-1]\n",
        "final_val_loss = best_model.history.history['val_loss'][-1]\n",
        "print(f\"Final Training Loss: {final_train_loss}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss}\")\n",
        "\n",
        "# 4. Printing the difference between the last-epoch training and validation losses\n",
        "loss_difference = final_train_loss - final_val_loss\n",
        "print(f\"Loss Difference (Train - Validation): {loss_difference}\")\n",
        "\n",
        "# Plotting the training and validation loss curves\n",
        "plt.plot(best_model.history.history['loss'], label='Training Loss')\n",
        "plt.plot(best_model.history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JREDKLBBaLO9"
      },
      "source": [
        "---\n",
        "### Step 6: Evaluation and Generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcGl3Z_paLO-"
      },
      "source": [
        "\n",
        "Now that you've determined the optimal set of hyperparameters, it's time to evaluate your optimized (tuned) model on the test data to gauge its performance in real-world scenarios, commonly known as inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJvz68YUaLO-"
      },
      "source": [
        "### <span style=\"color:chocolate\">Exercise 12:</span> Computing MSE (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Slnx7eraLO-"
      },
      "source": [
        "1. Calculate the MSE on both (X_train_std, Y_train_std) and (X_test_std, Y_test_std) datasets. Hint: You can utilize the <span style=\"color:chocolate\">model.evaluate()</span> method provided by tf.keras.\n",
        "\n",
        "2. Does the model demonstrate strong generalization capabilities? Provide an explanation based on your observations.\n",
        "\n",
        "4. Generate a plot to visualize the accuracy of the predictions. Plot the actual (observed) Y_test values on the x-axis and the predicted Y_test values on the y-axis. Additionally, include a 45-degree line in the plot for reference. Ensure that the plot contains appropriate axis labels and a title. Provide commentary on the model's fit based on this visualization. Hint: You can utilize the <span style=\"color:chocolate\">model.predict()</span> method available in tf.keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsuNdWBCaLPH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1.\n",
        "train_mse = best_model.evaluate(X_train_std, Y_train_std, verbose=0)\n",
        "test_mse = best_model.evaluate(X_test_std, Y_test_std, verbose=0)\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")\n",
        "\n",
        "# 2.\n",
        "if test_mse <= train_mse:\n",
        "    print(\"The model demonstrates strong generalization capabilities as the test MSE is lower than or equal to the training MSE (or at least relatively similar to the train MSE).\")\n",
        "else:\n",
        "    print(\"The model may be overfitting/does not demonstrate strong generalization capabilities because the test MSE is higher than the training MSE.\")\n",
        "\n",
        "# 3.\n",
        "y_pred = best_model.predict(X_test_std)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.scatter(Y_test_std, y_pred, color='blue', alpha=0.6)\n",
        "ax.axline([ax.get_xlim()[0], ax.get_ylim()[0]], [ax.get_xlim()[1], ax.get_ylim()[1]], color='red', linestyle='--', linewidth=1)\n",
        "plt.xlabel('Actual Price (Y_test)')\n",
        "plt.ylabel('Predicted Price (Y_pred)')\n",
        "plt.title('Actual vs Predicted Price (Test Set)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Q3. Since the points do not seem to lie on or near the 45-degree line (red dashed line), the model may have not made good predictions. \\nA perfect model would have all the points exactly on the line, but our model seems to have many points above and far from the line.\")\n",
        "print(\"This suggests that the model is overestimating the prices for many of the cars in the test set.\\nAlthough the model's predictions are not perfect, they are still generally close to the true values, indicating that it has captured some useful patterns, but there is room for further improvement in accuracy.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vuveMrbaLPH"
      },
      "source": [
        "----\n",
        "#### <span style=\"color:chocolate\">Additional practice question</span> (not graded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DDaL-9oaLPI"
      },
      "source": [
        "In Exercise 12, you reported an aggregated MSE. Let's revisit the exercise by:\n",
        "\n",
        "1. Performing a subgroup evaluation of the model. Specifically, calculate the test data MSE for the following makes: ['alfa-romero', 'audi', 'chevrolet', 'dodge', 'honda'].\n",
        "2. Addressing the question: Is the model \"fair\" across each make?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gycj7OfgaLPI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1.\n",
        "# makes_of_interest = ['alfa-romero', 'audi', 'chevrolet', 'dodge', 'honda']\n",
        "# test_data_filtered = X_test_std[Y_test_std.index.isin(makes_of_interest)]\n",
        "# y_pred_filtered = best_model.predict(test_data_filtered)\n",
        "# y_pred_filtered_original = (y_pred_filtered * Y_train_std.std()) + Y_train_std.mean()\n",
        "# y_test_filtered_original = (Y_test_std[Y_test_std.index.isin(makes_of_interest)] * Y_train_std.std()) + Y_train_std.mean()\n",
        "# mse_per_make = {}\n",
        "# for make in makes_of_interest:\n",
        "#     make_indices = test_data_filtered[test_data_filtered['make'] == make].index\n",
        "#     y_pred_make = y_pred_filtered_original[make_indices]\n",
        "#     y_test_make = y_test_filtered_original[make_indices]\n",
        "\n",
        "#     mse_per_make[make] = mean_squared_error(y_test_make, y_pred_make)\n",
        "# print(\"MSE for each make:\")\n",
        "# for make, mse in mse_per_make.items():\n",
        "#     print(f\"{make}: {mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQeq4Jl7MCjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "copyright"
      ],
      "name": "03 Linear Regression with Tensorflow.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}